19주차 수요일 메모( Kubernetes _ 2  kubespray, yaml )

어제에 이어서 쿠버네티스 설치부터 다시 돌아본다.

Kubernetes
   구글에서 개발하여 CNCF에서 관리하는 오픈소스 컨테이너 오케스트레이션 도구

Kubernetes의 주요 기능
 - Container Platform
 - Microservice Platform
 - 이식성 있는 Cloud Platform 

Kubernetes에서 제공하지 않는 기능
 - CI/CD 파이프라인 기능 미제공
 - 애플리케이션 레벨의 서비스 미제공
 - 로깅, 모니터링, 경고 솔루션 미제공
https://kubernetes.io/ko/docs/concepts/overview/components/
구성참조

 
컨트롤러 플레인 컴포넌트
Control Plane : Kubernetes Cluster를 제어하는 서버
-api서버 : 여러 쿠버네티스 노드들이 이것을 통해서 통신하게된다. 통신을해서 요청을하게되는 서버가 바로 api서버에 해당하며 컨트롤플레인의 핵심적인 역할을 맡는다. 여러 노드의 상태정보를 가진다.  API 서버는 쿠버네티스 컨트롤 플레인의 프론트 엔드이다. 
주요 구현은 kube-apiserver 이다. kube-apiserver는 수평으로 확장되도록 디자인되었다. 즉, 더 많은 인스턴스를 배포해서 확장할 수 있다. 여러 kube-apiserver 인스턴스를 실행하고, 인스턴스간의 트래픽을 균형있게 조절할 수 있다. 모든 구성요소가 api server를 거쳐 메세지를 주고받는다.
-kube-scheduler (sched) : 스케줄러이다. 컨테이너를 생성해달라고 요청했을 때 노드가 배정되지 않은 새로 생성된 파드(오브젝트) 를 감지하고, 실행할 노드를 선택 및 결정하는 컨트롤 플레인 컴포넌트이다.
-etcd: 엣시디라고 말하며, 모든 클러스터 데이터를 담는 쿠버네티스 뒷단의 저장소로 사용되는 일관성·고가용성 키-값 저장소(database)이다. etcd를 뒷단의 저장소로 사용한다면, 이 데이터를 백업하는 계획은 필수
-kube-controller-manager (C-M): 컨트롤러 프로세스를 실행하는 컨트롤 플레인 컴포넌트. 다음과 같은 컨트롤러가 있으며, 논리적으로, 각 컨트롤러는 분리된 프로세스이지만 복잡성을 낮추기 위해 모두 단일 바이너리로 컴파일되고 단일 프로세스 내에서 실행된다. 
•	노드 컨트롤러: 노드가 다운되었을 때 통지와 대응에 관한 책임을 가진다.
•	잡 컨트롤러: 일회성 작업을 나타내는 잡 오브젝트를 감시한 다음, 해당 작업을 완료할 때까지 동작하는 파드를 생성한다.
•	엔드포인트슬라이스 컨트롤러: (서비스와 파드 사이의 연결고리를 제공하기 위해) 엔드포인트슬라이스(EndpointSlice) 오브젝트를 채운다
•	서비스어카운트 컨트롤러: 새로운 네임스페이스에 대한 기본 서비스어카운트(ServiceAccount)를 생성한다.
-cloud-controller-manager (C-C-M) : 클라우드별 컨트롤 로직을 포함하는 쿠버네티스 컨트롤 플레인 컴포넌트이다. 매니저를 통해 클러스터를 클라우드 공급자의 API에 연결하고, 해당 클라우드 플랫폼과 상호 작용하는 컴포넌트와 클러스터와만 상호 작용하는 컴포넌트를 구분할 수 있게 해 준다.
다음 컨트롤러들은 클라우드 제공 사업자의 의존성을 가질 수 있다.*
•	노드 컨트롤러: 노드가 응답을 멈춘 후 클라우드 상에서 삭제되었는지 판별하기 위해 클라우드 제공 사업자에게 확인하는 것
•	라우트 컨트롤러: 기본 클라우드 인프라에 경로를 구성하는 것
•	서비스 컨트롤러: 클라우드 제공 사업자 로드밸런서를 생성, 업데이트 그리고 삭제하는 것

**클라우드 제공 사업자의 의존성을 가질 수 있다 란, = 제공해주는 서비스사업자의 클라우드서비스의 스펙, 기능들에 따라서 쿠버네티스와 연동시에 연결되는 동작이나 기능의 차이가 있을 수 있다는 뜻이다. 지원해주는 기능과 서비스가 있어야 한다는 것.

노드 컴포넌트
Node : Container를 실행하기 위한 Computing Resource를 제공하는 머신
kubelet : 클러스터의 각 노드에서 실행되는 에이전트역할을 수행하는 컴포넌트이다. Kubelet은 파드에서 컨테이너가 확실하게 동작하도록 관리한다. 모든 노드에 존재함
kube-proxy : 마찬가지로 모든 노드에 존재하며, 노드의 네트워크 규칙을 생성하고, 유지&관리한다. 이 네트워크 규칙이 내부 네트워크 세션이나 클러스터 바깥에서 파드로 네트워크 통신을 할 수 있도록 해준다. / =외부연결을 파드에 포워딩하는 역할을 담당

~~~~
쿠버네티스 설치 방법
1 . Kubeadm을 이용한 Kubernetes 설치
2 . Kubespray를 이용한 Kubernetes 설치 (ANSIBLE기반, 배포도구 이용) v
>동일하게 중요한 것은 swap off가 필수라는 것이다.
kube-control1  192.168.56.11
kube-node1  192.168.56.21
kube-node2  192.168.56.22
kube-node3  192.168.56.23
    ID : vagrant / PW : vagrant

# Kubespray를 이용한 Kubernetes 설치
C:\Users\user>cd kube
PS C:\Users\USER\kube> vagrant destroy -f 로 베이그런트 가상머신을 삭제해준다.
 
  (수정한 Vagrantfile로 대체한 뒤, vagrant up을 해준다)
간혹가다 안될때가 있는데, 이것은 VirtualBox VMs 폴더에 제대로 생성&삭제가 안되어서 생기는경우니까 유의 할 것.
C:\Users\user\kube>vagrant up

PS C:\Users\USER\kube> cd ..
PS C:\Users\USER> del .ssh\known_hosts
PS C:\Users\USER> cd kube

이다음은 SSH로 password로 로그인 가능하게 만들것이다(모든 노드에 적용하기)
PS C:\Users\USER\kube> vagrant ssh kube-control1
vagrant@kube-control1:~$ sudo -i 
root@kube-control1:~# vim /etc/ssh/sshd_config
:set nu  (엔터)
58G (엔터)   - 58번 행으로 이동
i  (Insert Mode 진입)
(58번 행) PasswordAuthentication yes
[Esc] 키 입력하여 Command 모드로 복귀 후
:wq   (엔터)
설정 적용을 위해 SSH 서비스 데몬 재시작
root@kube-control1:~# systemctl restart ssh 
>>이것을 모든 노드에 반복실행하면 된다.

이제 노드에 id/passwd로 로그인해보자.
vagrant@kube-control1:~$ ssh vagrant@192.168.56.11   (각 아이피로 접속)
vagrant@kube-control1:~$
vagrant@kube-node1:~$
vagrant@kube-node2:~$
vagrant@kube-node3:~$

-각 노드에서 스왑영역이 있지 않도록 체크한다.
vagrant@kube-control1:~$ cat /etc/fstab
LABEL=cloudimg-rootfs   /        ext4   discard,errors=remount-ro       0 1
#VAGRANT-BEGIN
# The contents below are automatically generated by Vagrant. Do not modify.
vagrant /vagrant vboxsf uid=1000,gid=1000,_netdev 0 0
#VAGRANT-END

# Kubespray를 통한 Kubernetes Cluster 배포
먼저 kube-control1호스트에서 ssh로 모든 노드에 한번씩 로그인해서 fingerprint를 남긴다.
ssh vagrant@localhost
ssh vagrant@127.0.0.1
ssh vagrant@192.168.56.11
ssh vagrant@192.168.56.21
ssh vagrant@192.168.56.22
ssh vagrant@192.168.56.23
ssh vagrant@kube-control1
ssh vagrant@kube-node1
ssh vagrant@kube-node1
ssh vagrant@kube-node2
ssh vagrant@kube-node3

vagrant@kube-control1:~$ ssh-keygen
vagrant@kube-control1:~$ ssh-copy-id vagrant@localhost
vagrant@localhost's password: vagrant 

SSH Key Pair 생성 및 공개키 배포(SSH 키 기반 인증 설정)
ssh-keygen
ssh-copy-id vagrant@localhost
ssh-copy-id vagrant@192.168.56.11
ssh-copy-id vagrant@192.168.56.21
ssh-copy-id vagrant@192.168.56.22
ssh-copy-id vagrant@192.168.56.23
--
control1 호스트에서 
cd ~
git clone -b v2.23.0 https://github.com/kubernetes-sigs/kubespray
cd ~/kubespray

sudo apt-get update
sudo apt-get install python3 python3-pip -y

sudo pip3 install -r requirements.txt

vagrant@kube-control1:~/kubespray$ ls -l inventory/
total 8
drwxrwxr-x 2 vagrant vagrant 4096 Dec 27 02:56 local
drwxrwxr-x 4 vagrant vagrant 4096 Dec 27 02:56 sample
vagrant@kube-control1:~/kubespray$ cp -rfp inventory/sample/ inventory/mycluster
vagrant@kube-control1:~/kubespray$ ls -l inventory/
total 12
drwxrwxr-x 2 vagrant vagrant 4096 Dec 27 02:56 local
drwxrwxr-x 4 vagrant vagrant 4096 Dec 27 02:56 mycluster
drwxrwxr-x 4 vagrant vagrant 4096 Dec 27 02:56 sample

편집기를 열어서 수정한다
vagrant@kube-control1:~/kubespray$ vi inventory/mycluster/inventory.ini
 
[all]
kube-control1    ansible_host=192.168.56.11    ip=192.168.56.11    ansible_connection=local
kube-node1    ansible_host=192.168.56.21    ip=192.168.56.21
kube-node2    ansible_host=192.168.56.22    ip=192.168.56.22
kube-node3    ansible_host=192.168.56.23    ip=192.168.56.23

[all:vars]
ansible_python_interpreter=/usr/bin/python3

[kube_control_plane]
kube-control1

[etcd]
kube-control1

[kube_node]
kube-node1
kube-node2
kube-node3
이렇게 수정한다.
코드설명>>
all 그룹에서- 인벤토리에 hostname을 등록하는 과정이다. ansible_host를 각 control1,node1,2,3와 연결할 ip를 연동한다. control1은 ansible_connection=local 방식으로 지정되어 연결되는 infra를 구성함
[all:vars] 그룹은
ansible_python_interpreter=/usr/bin/python3 앤서블이 사용할 인터프리터를 설정한것이고, 인벤토리에 정의된 모든 호스트에 적용되는 전역 변수가 포함되어 있다.
kube_control_plane 그룹은 -컨트롤플레인이 어떤 노드인지 
etcd 그룹은 - 어떤 노드(컴포넌트)가 키 밸류 db로 사용될지 
kube_node 그룹은 - 컨테이너를 실행할 수 있는 노드들이 각 어떤것인지 정의해주는 곳

다음 파일도 수정해준다.(변수 설정)
$ vi inventory/mycluster/group_vars/k8s_cluster/addons.yml
16 metrics_server_enabled: false 를 true로
100 ingress_nginx_enabled: false 를 true로 (인그레스 엔진을 설치하기)
177 metallb_enabled: false 를 true로 (로드밸런서 활성화)
205 metallb_config:
206   address_pools:
207     primary:
208       ip_range:
209       - 192.168.56.200-192.168.56.210
210       auto_assign: true
>>205~210까지는 yaml 파일 띄어쓰기를 잘 맞춰주어야 한다.(2칸씩)
219   layer2:
220     - primary  
>>여기도 들여쓰기레벨을 잘 맞춰준다.

 

그다음 변수를 수정한다.
vim inventory/mycluster/group_vars/k8s_cluster/k8s-cluster.yml 
129 kube_proxy_strict_arp: true
229 container_manager: docker


노드들이 서로 통신이 가능한지 이제 확인해본다.
vagrant@kube-control1:~/kubespray$ ansible all -i inventory/mycluster/inventory.ini -m ping
[WARNING]: Skipping callback plugin 'ara_default', unable to load
kube-control1 | SUCCESS => {
    "changed": false,
    "ping": "pong"
}
kube-node2 | SUCCESS => {
    "changed": false,
    "ping": "pong"
}
kube-node1 | SUCCESS => {
    "changed": false,
    "ping": "pong"
}
kube-node3 | SUCCESS => {
    "changed": false,
    "ping": "pong"
}
>>잘 핑퐁이 되는것을 알 수 있다.
vagrant@kube-control1:~/kubespray$ ansible all -i inventory/mycluster/inventory.ini -m apt -a "update_cache=yes" --become
[WARNING]: Skipping callback plugin 'ara_default', unable to load
kube-control1 | CHANGED => {
    "cache_update_time": 1703648309,
    "cache_updated": true,
    "changed": true
}

kube-node2 | CHANGED => {
    "cache_update_time": 1703648324,
    "cache_updated": true,
    "changed": true
}
kube-node1 | CHANGED => {
    "cache_update_time": 1703648324,
    "cache_updated": true,
    "changed": true
}
kube-node3 | CHANGED => {
    "cache_update_time": 1703648324,
    "cache_updated": true,
    "changed": true
}

vagrant@kube-control1:~/kubespray$ ansible-playbook -i inventory/mycluster/inventory.ini cluster.yml --become
PLAY [Check Ansible version] ***************************************************************************************************
Wednesday 27 December 2023  03:39:57 +0000 (0:00:00.020)       0:00:00.020 ****

TASK [Check 2.14.0 <= Ansible version < 2.15.0] ********************************************************************************
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}
Wednesday 27 December 2023  03:39:57 +0000 (0:00:00.031)       0:00:00.052 ****

TASK [Check that python netaddr is installed] **********************************************************************************
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}
Wednesday 27 December 2023  03:39:57 +0000 (0:00:00.088)       0:00:00.140 ****

TASK [Check that jinja is not too old (install via pip)] ***********************************************************************
ok: [localhost] => {
    "changed": false,
    "msg": "All assertions passed"
}
TASK [kubernetes/preinstall : Stop if either kube_control_plane or kube_node group is empty] ***********************************
fatal: [kube-control1]: FAILED! => {"msg": "The conditional check 'groups.get('kube_control_plane')' failed. The error was: Conditional is marked as unsafe, and cannot be evaluated."}
>>에러하나가 떴는데, 

"inventory/mycluster/inventory.ini” 를 다시 편집기로 열어서  수동으로 설정해줘야 할 듯 싶다.
 
>파이썬 모듈 호환성을 고려해야 했다.
#트러블슈팅
requirements.txt를 열어서 해당 내용을 추가한다.
vim requirements.txt
ansible==7.6.0
ansible-core==2.14.11
cryptography==41.0.1
jinja2==3.1.2
jmespath==1.0.1
MarkupSafe==2.1.3
netaddr==0.8.0
pbr==5.11.1
ruamel.yaml==0.17.31
ruamel.yaml.clib==0.2.7
>>ansible-core 2.14.11버전 추가를 하고 저장한다.
이후 다시 설치를 진행해본다.
$ ansible-playbook -i inventory/mycluster/inventory.ini cluster.yml --become
>>참고로, 수십분 이상이 걸리므로 유의할것.(20분 걸렸다)
 
끝나면 위의 캡쳐와 같이 나온다. 로그로는
PLAY RECAP *********************************************************************************************************************
kube-control1              : ok=764  changed=152  unreachable=0    failed=0    skipped=1283 rescued=0    ignored=8
kube-node1                 : ok=489  changed=86   unreachable=0    failed=0    skipped=786  rescued=0    ignored=1
kube-node2                 : ok=489  changed=86   unreachable=0    failed=0    skipped=784  rescued=0    ignored=1
kube-node3                 : ok=489  changed=86   unreachable=0    failed=0    skipped=784  rescued=0    ignored=1
localhost                  : ok=3    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0

Wednesday 27 December 2023  05:29:26 +0000 (0:00:00.229)       0:18:46.292 ****
===============================================================================
kubernetes-apps/metallb : Kubernetes Apps | Wait for MetalLB controller to be running ---------------------------------- 40.59s
container-engine/docker : Ensure docker packages are installed --------------------------------------------------------- 38.84s
network_plugin/calico : Check if calico ready -------------------------------------------------------------------------- 33.32s
download : Download_file | Download item ------------------------------------------------------------------------------- 29.14s
kubernetes/kubeadm : Join to cluster ----------------------------------------------------------------------------------- 27.81s
download : Download_container | Download image if required ------------------------------------------------------------- 27.17s
download : Download_container | Download image if required ------------------------------------------------------------- 23.06s
download : Download_container | Download image if required ------------------------------------------------------------- 22.19s
download : Download_container | Download image if required ------------------------------------------------------------- 20.63s
download : Download_container | Download image if required ------------------------------------------------------------- 17.23s
download : Download_file | Download item ------------------------------------------------------------------------------- 15.70s
download : Download_container | Download image if required ------------------------------------------------------------- 15.42s
kubernetes/control-plane : Kubeadm | Initialize first master ----------------------------------------------------------- 14.22s
download : Download_file | Download item ------------------------------------------------------------------------------- 13.35s
download : Download_container | Download image if required ------------------------------------------------------------- 12.86s
download : Download_container | Download image if required ------------------------------------------------------------- 12.53s
kubernetes-apps/ansible : Kubernetes Apps | Start Resources ------------------------------------------------------------ 12.52s
kubernetes/preinstall : Install packages requirements ------------------------------------------------------------------ 12.50s
etcdctl_etcdutl : Copy etcdctl and etcdutl binary from docker container ------------------------------------------------ 12.18s
download : Download_container | Download image if required ------------------------------------------------------------- 12.12s
vagrant@kube-control1:~/kubespray$

설치가 끝났으니 확인해본다.
vagrant@kube-control1:~/kubespray$ ls inventory/mycluster/
credentials  group_vars  inventory.ini  patches
vagrant@kube-control1:~/kubespray$ tree inventory/mycluster/
트리 패키지가 없어서 실행되지 않는다. 설치한다
vagrant@kube-control1:~/kubespray$ sudo apt-get install tree

다시 tree명령어를 실행하면 구조가 잘 나온다. 
vagrant@kube-control1:~/kubespray$ tree inventory/mycluster/
inventory/mycluster/
├── credentials
│   └── kubeadm_certificate_key.creds
├── group_vars
│   ├── all
│   │   ├── all.yml
│   │   ├── aws.yml
│   │   ├── azure.yml
│   │   ├── containerd.yml
│   │   ├── coreos.yml
│   │   ├── cri-o.yml
│   │   ├── docker.yml
│   │   ├── etcd.yml
│   │   ├── gcp.yml
│   │   ├── hcloud.yml
│   │   ├── huaweicloud.yml
│   │   ├── oci.yml
│   │   ├── offline.yml
│   │   ├── openstack.yml
│   │   ├── upcloud.yml
│   │   └── vsphere.yml
│   ├── etcd.yml
│   └── k8s_cluster
│       ├── addons.yml
│       ├── k8s-cluster.yml
│       ├── k8s-net-calico.yml
│       ├── k8s-net-cilium.yml
│       ├── k8s-net-flannel.yml
│       ├── k8s-net-kube-ovn.yml
│       ├── k8s-net-kube-router.yml
│       ├── k8s-net-macvlan.yml
│       └── k8s-net-weave.yml
├── inventory.ini
└── patches
    ├── kube-controller-manager+merge.yaml
    └── kube-scheduler+merge.yaml

5 directories, 30 files
~~~
>> tree inventory/mycluster/group_vars/ 명령으로 group_vars 디렉터리 구조또한 파악 가능하다.

#설치가 다 끝난 후 노드체크
 
vagrant@kube-control1:~/kubespray$ sudo -i
root@kube-control1:~# kubectl get node
NAME            STATUS   ROLES           AGE   VERSION
kube-control1   Ready    control-plane      18m   v1.27.5
kube-node1      Ready    <none>          17m   v1.27.5
kube-node2      Ready    <none>          17m   v1.27.5
kube-node3      Ready    <none>          17m   v1.27.5
>>이 명령을 통해서 모든 노드가 사용할 수 있는 상태인지 확인이 가능하다.

Kubernetes Cluster 관리를 위한 인증 정보 추가
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config


# 쿠버네티스에서 다루는 Object

쿠버네티스 기본 오브젝트
- 파드 (Pod)
파드는 kubernetes가 컨테이너를 다루는 기본 단위로, 하나 이상의 컨테이너를 포함하는 배포 단위를 말한다. 

kubectl 명령어 구조
  $ kubectl  SUBCOMMAND [OPTION]

쿠버네티스 가용 노드 목록/확인
vagrant@kube-control1:~$ kubectl get nodes 로 이용가능한 노드들을 확인할 수 있고,
vagrant@kube-control1:~$ kubectl get nodes -o wide 로 더 자세하게 알 수 있다.
 
vagrant@kube-control1:~$ kubectl get nodes -o wide
NAME            STATUS   ROLES           AGE   VERSION   INTERNAL-IP     EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION      CONTAINER-RUNTIME
kube-control1   Ready    control-plane   63m   v1.27.5   192.168.56.11   <none>        Ubuntu 22.04.3 LTS   5.15.0-91-generic   docker://20.10.20
kube-node1      Ready    <none>          62m   v1.27.5   192.168.56.21   <none>        Ubuntu 22.04.3 LTS   5.15.0-91-generic   docker://20.10.20
kube-node2      Ready    <none>          62m   v1.27.5   192.168.56.22   <none>        Ubuntu 22.04.3 LTS   5.15.0-91-generic   docker://20.10.20
kube-node3      Ready    <none>          62m   v1.27.5   192.168.56.23   <none>        Ubuntu 22.04.3 LTS   5.15.0-91-generic   docker://20.10.20
vagrant@kube-control1:~$ kubectl get nodes
NAME            STATUS   ROLES           AGE   VERSION
kube-control1   Ready    control-plane   64m   v1.27.5
kube-node1      Ready    <none>          63m   v1.27.5
kube-node2      Ready    <none>          63m   v1.27.5
kube-node3      Ready    <none>          63m   v1.27.5

쿠버네티스 Object 종류 및 API Version 확인
정말 다양한 오브젝트와 API가 존재한다.
vagrant@kube-control1:~$ kubectl api-resources

[실습] 디플로이먼트 생성해보기
-디플로이먼트 생성
vagrant@kube-control1:~$ kubectl create deployment myapp --image=nginx:latest
deployment.apps/myapp created

-Deployment,replicaset,pods 리소스 확인
vagrant@kube-control1:~$ kubectl get deployment,replicaset,pods
NAME                    READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/myapp   1/1     1            1           42s

NAME                              DESIRED   CURRENT   READY   AGE
replicaset.apps/myapp-fdd54f569   1         1         1       42s

NAME                        READY   STATUS    RESTARTS   AGE
pod/myapp-fdd54f569-6llzt   1/1     Running   0          42s

확인해보자
vagrant@kube-control1:~$ kubectl describe pod myapp-fdd54f569-6llzt

-서비스 노출
노드포트 타입의 서비스를 실행한다. (NodePort는 모든 노드의 지정된 포트를 통해 서비스에 액세스할 수 있도록 한다.) 
vagrant@kube-control1:~$ kubectl expose deployment myapp --port=80 --protocol=TCP --target-port=80 --name myapp-svc --type=NodePort
service/myapp-svc exposed
>>이를 실행하면, 클러스터 외부 네트워크에서 해당 포트(80/tcp)를 통해서 서비스에 액세스할 수 있게된다(웹으로 접근가능). 결과적으로 ‘myapp-svc’라는 이름의 서비스가 생성되며, 클러스터 내 모든 노드에서도 해당 서비스를 사용할 수 있게 된다.

vagrant@kube-control1:~$ kubectl get services
NAME         TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE
kubernetes   ClusterIP   10.233.0.1     <none>        443/TCP        81m
myapp-svc    NodePort    10.233.17.54   <none>        80:30234/TCP   26s

vagrant@kube-control1:~$ curl http://192.168.56.21:30234
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
<style>
html { color-scheme: light dark; }
body { width: 35em; margin: 0 auto;
font-family: Tahoma, Verdana, Arial, sans-serif; }
</style>
</head>
<body>
<h1>Welcome to nginx!</h1>
<p>If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.</p>

<p>For online documentation and support please refer to
<a href="http://nginx.org/">nginx.org</a>.<br/>
Commercial support is available at
<a href="http://nginx.com/">nginx.com</a>.</p>

<p><em>Thank you for using nginx.</em></p>
</body>
</html>
  
>>이렇게 nginx 홈페이지를 열 수 있었다.

# 오브젝트 삭제하기
vagrant@kube-control1:~$ kubectl get service
NAME         TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE
kubernetes   ClusterIP   10.233.0.1     <none>        443/TCP        89m
myapp-svc    NodePort    10.233.17.54   <none>        80:30234/TCP   8m34s
vagrant@kube-control1:~$ kubectl delete services myapp-svc
service "myapp-svc" deleted
vagrant@kube-control1:~$ kubectl delete deployments myapp-svc
Error from server (NotFound): deployments.apps "myapp-svc" not found


# YAML 문법
•	YAML의 문자열은 UTF-8 또는 UTF-16의 유니코드 문자 집합을 사용함.
•	공백 문자를 이용하여 들여 쓰기로 계층구조를 구분함.
    ‒ 탭 문자는 들여 쓰기에 사용하지 않음.
•	하나의 스트림에 있는 여러 개의 YAML 문서를 구분하기 위해 시작은 하이픈 3개(---), 끝은 마침표 3개(...)를 사용함.
•	주석은 #으로 표시하며, 한 줄이 끝날 때까지 유효함.
•	YAML 파일의 확장자는 yml 또는 yaml을 일반적으로 사용함.

YAML 파일 작성을 위한 VI Editor 설정
$ vim ~/.vimrc
syntax on
autocmd FileType yaml setlocal ts=2 sts=2 sw=2 expandtab autoindent
 
>>yaml 타입의 파일에서 두칸씩 입력되도록 하는 설정을 마쳤다.

# yaml파일 실습
간단하게 test.yaml 하나 만들어서 테스트한다.
 
저장은 하지 않고 테스트만 해봤다.

vagrant@kube-control1:~$ mkdir work
vagrant@kube-control1:~$ cd work
vagrant@kube-control1:~/work$ mkdir 20231227
vagrant@kube-control1:~/work$ cd 20231227/
vagrant@kube-control1:~/work/20231227$ pwd
/home/vagrant/work/20231227
vagrant@kube-control1:~/work/20231227$ vim example-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: example-pod
spec:
  containers:
  - name: example
    image: devops2341/go-myweb:latest
    ports:
    - containerPort: 8080
      protocol: TCP

*들여쓰기레벨을 정말정말정말 주의하자.

Kubernetes 오브젝트 생성(Pod)
$ kubectl create -f example-pod.yaml 

팟 실행 여부 확인
vagrant@kube-control1:~/work/20231227$ kubectl get pods
NAME                    READY   STATUS    RESTARTS   AGE
example-pod             1/1     Running   0          9s
myapp-fdd54f569-6llzt   1/1     Running   0          59m

vagrant@kube-control1:~/work/20231227$ kubectl describe pods example-pod
 
이제 웹에 접근을 해보자.
vagrant@kube-control1:~/work/20231227$ curl http://10.233.73.67:8080
Hello World!
example-pod

Kubernetes v1.27.7 (kubespray)
https://www.dropbox.com/scl/fo/3fezizwzaml7w5i1h8mqr/h?rlkey=nzucdt63sdpmxk9zgi22cmq14&dl=0



